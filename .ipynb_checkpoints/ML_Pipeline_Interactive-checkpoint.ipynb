{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62019375",
   "metadata": {},
   "source": [
    "# Risk Claims ML Pipeline - Interactive Tutorial\n",
    "\n",
    "## Complete 10-Stage Machine Learning Pipeline\n",
    "\n",
    "**Project:** Insurance Claims Risk Classification  \n",
    "**Goal:** Predict whether a claim is high-risk or low-risk  \n",
    "**Dataset:** 800 training records with 14 features  \n",
    "**Model:** Random Forest Classifier\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This notebook walks through all **10 essential stages of an ML pipeline**:\n",
    "\n",
    "1. üì• **Data Ingestion** - Load data from files\n",
    "2. ‚úÖ **Data Validation** - Check data quality\n",
    "3. üßπ **Data Preprocessing** - Clean and prepare data\n",
    "4. ‚öôÔ∏è **Feature Engineering** - Create meaningful features\n",
    "5. üéØ **Model Training** - Train ML algorithms\n",
    "6. üìä **Model Evaluation** - Assess performance\n",
    "7. üèÜ **Model Selection** - Choose best model\n",
    "8. üöÄ **Model Deployment** - Save for production\n",
    "9. üìà **Monitoring** - Track performance\n",
    "10. üîÑ **Model Retraining** - Update when needed\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Understanding these 10 stages is essential for building **production-ready ML systems**. This notebook demonstrates best practices in a simplified, easy-to-understand format.\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103c030",
   "metadata": {},
   "source": [
    "## üì¶ Setup: Import Required Libraries\n",
    "\n",
    "Before we start, let's import all the necessary Python libraries:\n",
    "\n",
    "- **pandas**: Data manipulation and analysis\n",
    "- **numpy**: Numerical computations\n",
    "- **scikit-learn**: Machine learning algorithms and tools\n",
    "- **matplotlib/seaborn**: Data visualization\n",
    "- **joblib**: Model serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import scikit-learn components\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Import joblib for model serialization\n",
    "import joblib\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952e613",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 1: üì• Data Ingestion\n",
    "\n",
    "### What is Data Ingestion?\n",
    "\n",
    "**Data Ingestion** is the first stage of any ML pipeline where we load raw data from various sources into our system for processing.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- It's the foundation of the entire pipeline\n",
    "- Ensures data is accessible for analysis\n",
    "- Validates that source files exist and are readable\n",
    "- Sets up the initial data structure\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "We load insurance claims data from a CSV file containing:\n",
    "- **800 training records** with 14 features\n",
    "- Information about claims, customers, and policies\n",
    "- Risk labels (high/low) for supervised learning\n",
    "\n",
    "### Common Data Sources:\n",
    "- üìÅ Files (CSV, JSON, Excel)\n",
    "- üóÑÔ∏è Databases (PostgreSQL, MySQL)\n",
    "- ‚òÅÔ∏è Cloud Storage (S3, Azure Blob)\n",
    "- üåê APIs (REST, GraphQL)\n",
    "\n",
    "Let's load our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Data Ingestion\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 1: DATA INGESTION\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load data from CSV file\n",
    "data_path = 'data/sample_claims_train.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Data loaded successfully from {data_path}\")\n",
    "    print(f\"üìä Dataset shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: File not found at {data_path}\")\n",
    "    \n",
    "# Display first few records\n",
    "print(\"\\nüìã First 5 records:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset structure\n",
    "print(\"üîç Dataset Information:\")\n",
    "print(\"\\nColumn Names and Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nüìè Dataset Dimensions: {df.shape}\")\n",
    "print(f\"\\nüéØ Target Variable: 'risk_level' ‚Üí {df['risk_level'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae77707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "risk_counts = df['risk_level'].value_counts()\n",
    "axes[0].bar(risk_counts.index, risk_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Risk Level Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Risk Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(risk_counts.values):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Risk Level Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Class Imbalance Ratio: {risk_counts.iloc[0] / risk_counts.iloc[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e42eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 2: ‚úÖ Data Validation\n",
    "\n",
    "### What is Data Validation?\n",
    "\n",
    "**Data Validation** ensures the quality and integrity of your data before processing. It's like a quality control checkpoint.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Catches data quality issues early\n",
    "- Prevents errors in downstream stages\n",
    "- Ensures data meets expected schema\n",
    "- Identifies missing or invalid values\n",
    "\n",
    "### What We Check:\n",
    "\n",
    "1. **Schema Validation**: Correct column names and types\n",
    "2. **Missing Values**: Null or NaN entries\n",
    "3. **Data Types**: Numeric vs. categorical\n",
    "4. **Value Ranges**: Outliers and invalid values\n",
    "5. **Duplicates**: Redundant records\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Define expected schema upfront\n",
    "- Set acceptable value ranges\n",
    "- Document validation rules\n",
    "- Log validation failures\n",
    "- Implement data quality metrics\n",
    "\n",
    "Let's validate our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30bbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Data Validation\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 2: DATA VALIDATION\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Required columns\n",
    "required_columns = [\n",
    "    'claim_id', 'customer_id', 'claim_amount', 'claim_type', \n",
    "    'claim_date', 'policy_id', 'customer_age', 'policy_duration',\n",
    "    'policy_start_date', 'policy_coverage', 'previous_claims',\n",
    "    'claim_description', 'location', 'risk_level'\n",
    "]\n",
    "\n",
    "validation_results = {\n",
    "    'schema_valid': True,\n",
    "    'missing_values': 0,\n",
    "    'duplicates': 0,\n",
    "    'invalid_ranges': 0\n",
    "}\n",
    "\n",
    "# 1. Check required columns\n",
    "print(\"\\n1Ô∏è‚É£ Checking Schema...\")\n",
    "missing_cols = set(required_columns) - set(df.columns)\n",
    "if missing_cols:\n",
    "    print(f\"   ‚ùå Missing columns: {missing_cols}\")\n",
    "    validation_results['schema_valid'] = False\n",
    "else:\n",
    "    print(f\"   ‚úÖ All {len(required_columns)} required columns present\")\n",
    "\n",
    "# 2. Check for missing values\n",
    "print(\"\\n2Ô∏è‚É£ Checking Missing Values...\")\n",
    "missing_count = df.isnull().sum().sum()\n",
    "validation_results['missing_values'] = missing_count\n",
    "if missing_count > 0:\n",
    "    print(f\"   ‚ö†Ô∏è Found {missing_count} missing values\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "else:\n",
    "    print(\"   ‚úÖ No missing values found\")\n",
    "\n",
    "# 3. Check for duplicates\n",
    "print(\"\\n3Ô∏è‚É£ Checking Duplicates...\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "validation_results['duplicates'] = duplicate_count\n",
    "if duplicate_count > 0:\n",
    "    print(f\"   ‚ö†Ô∏è Found {duplicate_count} duplicate rows\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No duplicates found\")\n",
    "\n",
    "# 4. Check value ranges\n",
    "print(\"\\n4Ô∏è‚É£ Checking Value Ranges...\")\n",
    "invalid_count = 0\n",
    "\n",
    "# Age should be between 18 and 100\n",
    "if (df['customer_age'] < 18).any() or (df['customer_age'] > 100).any():\n",
    "    invalid_age = ((df['customer_age'] < 18) | (df['customer_age'] > 100)).sum()\n",
    "    print(f\"   ‚ö†Ô∏è Invalid ages: {invalid_age} records\")\n",
    "    invalid_count += invalid_age\n",
    "else:\n",
    "    print(\"   ‚úÖ Customer ages valid (18-100)\")\n",
    "\n",
    "# Claim amount should be positive\n",
    "if (df['claim_amount'] <= 0).any():\n",
    "    invalid_amounts = (df['claim_amount'] <= 0).sum()\n",
    "    print(f\"   ‚ö†Ô∏è Invalid claim amounts: {invalid_amounts} records\")\n",
    "    invalid_count += invalid_amounts\n",
    "else:\n",
    "    print(\"   ‚úÖ Claim amounts valid (> 0)\")\n",
    "\n",
    "validation_results['invalid_ranges'] = invalid_count\n",
    "\n",
    "# 5. Data Quality Score\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "total_checks = 4\n",
    "passed_checks = sum([\n",
    "    validation_results['schema_valid'],\n",
    "    validation_results['missing_values'] == 0,\n",
    "    validation_results['duplicates'] == 0,\n",
    "    validation_results['invalid_ranges'] == 0\n",
    "])\n",
    "quality_score = (passed_checks / total_checks) * 100\n",
    "\n",
    "print(f\"üìä DATA QUALITY SCORE: {quality_score:.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if quality_score == 100:\n",
    "    print(\"‚úÖ Data validation PASSED - Ready for preprocessing!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data validation found issues - Review and clean data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc67c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02864f19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 3: üßπ Data Preprocessing\n",
    "\n",
    "### What is Data Preprocessing?\n",
    "\n",
    "**Data Preprocessing** cleans and transforms raw data into a format suitable for machine learning models.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- ML algorithms require clean, consistent data\n",
    "- Improves model accuracy and performance\n",
    "- Handles missing values and outliers\n",
    "- Standardizes data formats\n",
    "\n",
    "### Common Preprocessing Steps:\n",
    "\n",
    "1. **Handle Missing Values**: Imputation or removal\n",
    "2. **Remove Duplicates**: Eliminate redundant records\n",
    "3. **Fix Data Types**: Convert strings to dates, etc.\n",
    "4. **Handle Outliers**: Cap, remove, or transform\n",
    "5. **Normalize Text**: Lowercase, trim whitespace\n",
    "6. **Parse Dates**: Extract components (year, month, day)\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "- Remove any duplicates\n",
    "- Convert date strings to datetime objects\n",
    "- Prepare data for feature engineering\n",
    "\n",
    "Let's clean our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Data Preprocessing\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 3: DATA PREPROCESSING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_clean = df.copy()\n",
    "original_shape = df_clean.shape\n",
    "\n",
    "print(f\"\\nüìä Original dataset: {original_shape[0]} rows √ó {original_shape[1]} columns\")\n",
    "\n",
    "# 1. Remove duplicates\n",
    "print(\"\\n1Ô∏è‚É£ Removing Duplicates...\")\n",
    "duplicates_before = df_clean.duplicated().sum()\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "duplicates_removed = duplicates_before - df_clean.duplicated().sum()\n",
    "print(f\"   üóëÔ∏è Removed {duplicates_removed} duplicate rows\")\n",
    "\n",
    "# 2. Convert date columns to datetime\n",
    "print(\"\\n2Ô∏è‚É£ Converting Date Columns...\")\n",
    "date_columns = ['claim_date', 'policy_start_date']\n",
    "for col in date_columns:\n",
    "    df_clean[col] = pd.to_datetime(df_clean[col])\n",
    "    print(f\"   ‚úÖ Converted '{col}' to datetime\")\n",
    "\n",
    "# 3. Handle missing values (if any)\n",
    "print(\"\\n3Ô∏è‚É£ Handling Missing Values...\")\n",
    "missing_before = df_clean.isnull().sum().sum()\n",
    "if missing_before > 0:\n",
    "    # Fill numerical columns with median\n",
    "    numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        if df_clean[col].isnull().any():\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "            print(f\"   üîß Filled missing values in '{col}' with median\")\n",
    "    \n",
    "    # Fill categorical columns with mode\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().any():\n",
    "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "            print(f\"   üîß Filled missing values in '{col}' with mode\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No missing values to handle\")\n",
    "\n",
    "# 4. Normalize text fields\n",
    "print(\"\\n4Ô∏è‚É£ Normalizing Text Fields...\")\n",
    "text_columns = ['claim_type', 'location']\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].str.strip().str.lower()\n",
    "    print(f\"   ‚úÖ Normalized '{col}' (lowercase, trimmed)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ Preprocessing Complete!\")\n",
    "print(f\"üìä Final dataset: {df_clean.shape[0]} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(f\"üìâ Rows removed: {original_shape[0] - df_clean.shape[0]}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739c45f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 4: ‚öôÔ∏è Feature Engineering\n",
    "\n",
    "### What is Feature Engineering?\n",
    "\n",
    "**Feature Engineering** is the process of creating new features or transforming existing ones to improve model performance.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Can dramatically improve model accuracy\n",
    "- Captures domain knowledge\n",
    "- Makes patterns more visible to algorithms\n",
    "- Reduces dimensionality\n",
    "\n",
    "### Common Techniques:\n",
    "\n",
    "1. **Date Features**: Extract year, month, day, day of week\n",
    "2. **Derived Features**: Calculate ratios, differences\n",
    "3. **Encoding Categorical**: One-hot, label encoding\n",
    "4. **Binning**: Group continuous values into categories\n",
    "5. **Interactions**: Combine multiple features\n",
    "6. **Scaling**: Normalize numerical features\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "1. **Create `policy_age`**: Time between policy start and claim date\n",
    "2. **Encode categorical variables**: claim_type, location\n",
    "3. **Scale numerical features**: StandardScaler for uniform range\n",
    "4. **Extract useful features** from dates and text\n",
    "\n",
    "Let's engineer our features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4: Feature Engineering\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 4: FEATURE ENGINEERING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_features = df_clean.copy()\n",
    "\n",
    "# 1. Create derived features\n",
    "print(\"\\n1Ô∏è‚É£ Creating Derived Features...\")\n",
    "\n",
    "# Policy age: difference between claim date and policy start\n",
    "df_features['policy_age'] = (df_features['claim_date'] - df_features['policy_start_date']).dt.days\n",
    "print(f\"   ‚úÖ Created 'policy_age' (days between policy start and claim)\")\n",
    "\n",
    "# Claim to coverage ratio\n",
    "df_features['claim_coverage_ratio'] = df_features['claim_amount'] / df_features['policy_coverage']\n",
    "print(f\"   ‚úÖ Created 'claim_coverage_ratio' (claim amount / coverage)\")\n",
    "\n",
    "# 2. Encode categorical variables\n",
    "print(\"\\n2Ô∏è‚É£ Encoding Categorical Variables...\")\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_features = ['claim_type', 'location']\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_features[f'{col}_encoded'] = le.fit_transform(df_features[col])\n",
    "    label_encoders[col] = le\n",
    "    unique_count = len(le.classes_)\n",
    "    print(f\"   ‚úÖ Encoded '{col}' ‚Üí {unique_count} unique values\")\n",
    "\n",
    "# 3. Select features for modeling\n",
    "print(\"\\n3Ô∏è‚É£ Selecting Features for Modeling...\")\n",
    "\n",
    "feature_columns = [\n",
    "    'claim_amount',\n",
    "    'customer_age', \n",
    "    'policy_duration',\n",
    "    'policy_coverage',\n",
    "    'previous_claims',\n",
    "    'policy_age',\n",
    "    'claim_coverage_ratio',\n",
    "    'claim_type_encoded',\n",
    "    'location_encoded'\n",
    "]\n",
    "\n",
    "# Prepare feature matrix and target\n",
    "X = df_features[feature_columns].copy()\n",
    "y = df_features['risk_level'].copy()\n",
    "\n",
    "print(f\"   ‚úÖ Selected {len(feature_columns)} features:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"      {i}. {col}\")\n",
    "\n",
    "# 4. Encode target variable\n",
    "print(\"\\n4Ô∏è‚É£ Encoding Target Variable...\")\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "print(f\"   ‚úÖ Encoded target: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}\")\n",
    "\n",
    "# 5. Scale numerical features\n",
    "print(\"\\n5Ô∏è‚É£ Scaling Numerical Features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=feature_columns)\n",
    "print(f\"   ‚úÖ Applied StandardScaler to all {len(feature_columns)} features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Feature Engineering Complete!\")\n",
    "print(f\"üìä Feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"üéØ Target vector shape: {y_encoded.shape}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = X_scaled.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° High correlations (> 0.7) may indicate redundant features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bc561",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 5: üéØ Model Training\n",
    "\n",
    "### What is Model Training?\n",
    "\n",
    "**Model Training** is where we teach a machine learning algorithm to recognize patterns in our data.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Core of the ML pipeline\n",
    "- Algorithm learns from data\n",
    "- Creates predictive model\n",
    "- Finds optimal parameters\n",
    "\n",
    "### Training Process:\n",
    "\n",
    "1. **Split Data**: Training vs. testing sets (80/20 split)\n",
    "2. **Choose Algorithm**: Random Forest, XGBoost, Neural Network\n",
    "3. **Set Hyperparameters**: Model configuration\n",
    "4. **Fit Model**: Learn from training data\n",
    "5. **Avoid Overfitting**: Balance complexity vs. generalization\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "- **Algorithm**: Random Forest Classifier\n",
    "- **Why Random Forest?**\n",
    "  - Handles non-linear relationships\n",
    "  - Resistant to overfitting\n",
    "  - Provides feature importance\n",
    "  - Works well with imbalanced data\n",
    "  \n",
    "- **Hyperparameters**:\n",
    "  - `n_estimators`: 50 (number of trees)\n",
    "  - `max_depth`: 10 (tree depth)\n",
    "  - `min_samples_split`: 5\n",
    "  - `min_samples_leaf`: 2\n",
    "\n",
    "Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 5: Model Training\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 5: MODEL TRAINING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Split data into training and testing sets\n",
    "print(\"\\n1Ô∏è‚É£ Splitting Data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_encoded  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
    "print(f\"   üìä Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_dist = pd.Series(y_train).value_counts()\n",
    "test_dist = pd.Series(y_test).value_counts()\n",
    "print(f\"\\n   Training distribution: {dict(zip(le_target.classes_, train_dist.values))}\")\n",
    "print(f\"   Test distribution: {dict(zip(le_target.classes_, test_dist.values))}\")\n",
    "\n",
    "# 2. Initialize Random Forest model\n",
    "print(\"\\n2Ô∏è‚É£ Initializing Random Forest Classifier...\")\n",
    "model_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1  # Use all CPU cores\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(**model_params)\n",
    "print(f\"   ‚úÖ Model initialized with parameters:\")\n",
    "for param, value in model_params.items():\n",
    "    print(f\"      ‚Ä¢ {param}: {value}\")\n",
    "\n",
    "# 3. Train the model\n",
    "print(\"\\n3Ô∏è‚É£ Training Model...\")\n",
    "start_time = datetime.now()\n",
    "rf_model.fit(X_train, y_train)\n",
    "training_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"   ‚úÖ Model trained successfully!\")\n",
    "print(f\"   ‚è±Ô∏è Training time: {training_time:.2f} seconds\")\n",
    "print(f\"   üå≤ Number of trees: {rf_model.n_estimators}\")\n",
    "print(f\"   üìè Max tree depth: {rf_model.max_depth}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Model Training Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab55c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 6: üìä Model Evaluation\n",
    "\n",
    "### What is Model Evaluation?\n",
    "\n",
    "**Model Evaluation** measures how well our trained model performs on unseen data.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Validates model effectiveness\n",
    "- Identifies overfitting or underfitting\n",
    "- Guides model improvements\n",
    "- Ensures real-world viability\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "1. **Accuracy**: Overall correct predictions (%)\n",
    "2. **Precision**: Of positive predictions, how many are correct?\n",
    "3. **Recall**: Of actual positives, how many did we find?\n",
    "4. **F1-Score**: Harmonic mean of precision and recall\n",
    "5. **Confusion Matrix**: Breakdown of predictions vs. actuals\n",
    "\n",
    "### What's a Good Score?\n",
    "\n",
    "- **Accuracy > 80%**: Generally good\n",
    "- **90-95%**: Excellent\n",
    "- **> 95%**: Outstanding (but check for overfitting!)\n",
    "- **100%**: Suspicious - may indicate data leakage\n",
    "\n",
    "### For Imbalanced Data:\n",
    "\n",
    "- Accuracy can be misleading\n",
    "- Focus on **precision** and **recall**\n",
    "- Use **F1-score** for balance\n",
    "- Examine **confusion matrix** carefully\n",
    "\n",
    "Let's evaluate our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdebe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 6: Model Evaluation\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 6: MODEL EVALUATION\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Make predictions\n",
    "print(\"\\n1Ô∏è‚É£ Making Predictions...\")\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "print(f\"   ‚úÖ Generated predictions for {len(y_test)} test samples\")\n",
    "\n",
    "# 2. Calculate metrics for training set\n",
    "print(\"\\n2Ô∏è‚É£ Training Set Performance:\")\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(f\"   üìä Accuracy:  {train_accuracy*100:.2f}%\")\n",
    "print(f\"   üéØ Precision: {train_precision*100:.2f}%\")\n",
    "print(f\"   üîç Recall:    {train_recall*100:.2f}%\")\n",
    "print(f\"   ‚öñÔ∏è F1-Score:  {train_f1*100:.2f}%\")\n",
    "\n",
    "# 3. Calculate metrics for test set\n",
    "print(\"\\n3Ô∏è‚É£ Test Set Performance:\")\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"   üìä Accuracy:  {test_accuracy*100:.2f}%\")\n",
    "print(f\"   üéØ Precision: {test_precision*100:.2f}%\")\n",
    "print(f\"   üîç Recall:    {test_recall*100:.2f}%\")\n",
    "print(f\"   ‚öñÔ∏è F1-Score:  {test_f1*100:.2f}%\")\n",
    "\n",
    "# 4. Check for overfitting\n",
    "print(\"\\n4Ô∏è‚É£ Overfitting Check:\")\n",
    "accuracy_diff = train_accuracy - test_accuracy\n",
    "if accuracy_diff < 0.05:\n",
    "    print(f\"   ‚úÖ No significant overfitting (diff: {accuracy_diff*100:.2f}%)\")\n",
    "elif accuracy_diff < 0.10:\n",
    "    print(f\"   ‚ö†Ô∏è Slight overfitting detected (diff: {accuracy_diff*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Significant overfitting (diff: {accuracy_diff*100:.2f}%)\")\n",
    "\n",
    "# 5. Generate classification report\n",
    "print(\"\\n5Ô∏è‚É£ Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=le_target.classes_))\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76553078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix - counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_target.classes_, \n",
    "            yticklabels=le_target.classes_,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "# Confusion matrix - percentages\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Greens',\n",
    "            xticklabels=le_target.classes_, \n",
    "            yticklabels=le_target.classes_,\n",
    "            ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "axes[1].set_title('Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Actual', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate specific metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nüìä Confusion Matrix Breakdown:\")\n",
    "print(f\"   True Negatives:  {tn} ({tn/cm.sum()*100:.1f}%)\")\n",
    "print(f\"   False Positives: {fp} ({fp/cm.sum()*100:.1f}%)\")\n",
    "print(f\"   False Negatives: {fn} ({fn/cm.sum()*100:.1f}%)\")\n",
    "print(f\"   True Positives:  {tp} ({tp/cm.sum()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487afdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Top 5 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"   {row['feature']:25s} ‚Üí {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fdee1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 7: üèÜ Model Selection\n",
    "\n",
    "### What is Model Selection?\n",
    "\n",
    "**Model Selection** is the process of choosing the best model from multiple candidates based on performance metrics.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Different algorithms have different strengths\n",
    "- Ensures best performance for your use case\n",
    "- Balances accuracy vs. complexity\n",
    "- Considers production constraints\n",
    "\n",
    "### Selection Criteria:\n",
    "\n",
    "1. **Performance Metrics**: Accuracy, F1-score, AUC-ROC\n",
    "2. **Training Time**: How long to train?\n",
    "3. **Inference Speed**: How fast are predictions?\n",
    "4. **Model Size**: Memory footprint\n",
    "5. **Interpretability**: Can we explain predictions?\n",
    "6. **Maintenance**: Easy to update and retrain?\n",
    "\n",
    "### Common Algorithms:\n",
    "\n",
    "| Algorithm | Pros | Cons |\n",
    "|-----------|------|------|\n",
    "| **Random Forest** | High accuracy, handles non-linearity | Slower inference, larger size |\n",
    "| **XGBoost** | State-of-art performance | Complex tuning, longer training |\n",
    "| **Logistic Regression** | Fast, interpretable | Assumes linearity |\n",
    "| **Neural Networks** | Handles complex patterns | Requires more data, black box |\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "We're using **Random Forest** because:\n",
    "- ‚úÖ Excellent performance on tabular data\n",
    "- ‚úÖ Handles class imbalance well\n",
    "- ‚úÖ Provides feature importance\n",
    "- ‚úÖ Minimal hyperparameter tuning needed\n",
    "\n",
    "For production, we'd compare multiple models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 7: Model Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 7: MODEL SELECTION\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# In production, we'd compare multiple models\n",
    "# For this tutorial, we'll demonstrate the selection process\n",
    "\n",
    "print(\"\\nüîç Model Comparison (Simulated):\\n\")\n",
    "\n",
    "# Store our Random Forest results\n",
    "models_comparison = {\n",
    "    'Random Forest': {\n",
    "        'accuracy': test_accuracy,\n",
    "        'f1_score': test_f1,\n",
    "        'training_time': training_time,\n",
    "        'model_size': '123 KB',\n",
    "        'interpretability': 'Medium'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simulate comparison with other algorithms (for demonstration)\n",
    "print(\"üìä Performance Comparison:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<20} {'Accuracy':<12} {'F1-Score':<12} {'Train Time':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, metrics in models_comparison.items():\n",
    "    print(f\"{model_name:<20} {metrics['accuracy']*100:>10.2f}% {metrics['f1_score']*100:>10.2f}% {metrics['training_time']:>10.2f}s\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Selection decision\n",
    "print(\"\\nüèÜ Model Selection Decision:\")\n",
    "print(f\"   Selected Model: Random Forest Classifier\")\n",
    "print(f\"   Reason: Best balance of accuracy, speed, and interpretability\")\n",
    "print(f\"   \")\n",
    "print(f\"   Key Metrics:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {test_f1*100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Training Time: {training_time:.2f}s\")\n",
    "print(f\"   ‚Ä¢ Feature Importance: Available ‚úÖ\")\n",
    "\n",
    "print(\"\\nüí° Production Recommendation:\")\n",
    "print(\"   For real-world deployment, also evaluate:\")\n",
    "print(\"   ‚Ä¢ XGBoost (potentially higher accuracy)\")\n",
    "print(\"   ‚Ä¢ LightGBM (faster training on large datasets)\")\n",
    "print(\"   ‚Ä¢ Ensemble methods (combine multiple models)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Model Selected: Random Forest\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7692996",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 8: üöÄ Model Deployment\n",
    "\n",
    "### What is Model Deployment?\n",
    "\n",
    "**Model Deployment** is the process of saving your trained model and making it available for production use.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Preserves trained model for future use\n",
    "- Enables production predictions\n",
    "- Versioning and reproducibility\n",
    "- Separates training from inference\n",
    "\n",
    "### Deployment Methods:\n",
    "\n",
    "1. **File-Based**: Save model to disk (pickle, joblib)\n",
    "2. **API Service**: REST API (Flask, FastAPI)\n",
    "3. **Cloud**: AWS SageMaker, Azure ML, GCP AI Platform\n",
    "4. **Edge**: TensorFlow Lite, ONNX\n",
    "5. **Batch**: Scheduled predictions on large datasets\n",
    "\n",
    "### What to Save:\n",
    "\n",
    "1. **Trained Model**: The algorithm with learned parameters\n",
    "2. **Preprocessing Objects**: Scalers, encoders\n",
    "3. **Feature Names**: Column order and names\n",
    "4. **Metadata**: Version, date, metrics, configuration\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "We'll save:\n",
    "- ‚úÖ Random Forest model (`risk_model.pkl`)\n",
    "- ‚úÖ StandardScaler (`scaler.pkl`)\n",
    "- ‚úÖ Label encoders (`encoders.pkl`)\n",
    "- ‚úÖ Model metadata (`metadata.json`)\n",
    "\n",
    "Let's deploy our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 8: Model Deployment\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 8: MODEL DEPLOYMENT\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# 1. Save the trained model\n",
    "print(\"\\n1Ô∏è‚É£ Saving Trained Model...\")\n",
    "model_path = 'models/risk_model.pkl'\n",
    "joblib.dump(rf_model, model_path)\n",
    "model_size = os.path.getsize(model_path) / 1024\n",
    "print(f\"   ‚úÖ Model saved to: {model_path}\")\n",
    "print(f\"   üíæ File size: {model_size:.2f} KB\")\n",
    "\n",
    "# 2. Save the scaler\n",
    "print(\"\\n2Ô∏è‚É£ Saving StandardScaler...\")\n",
    "scaler_path = 'models/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "scaler_size = os.path.getsize(scaler_path) / 1024\n",
    "print(f\"   ‚úÖ Scaler saved to: {scaler_path}\")\n",
    "print(f\"   üíæ File size: {scaler_size:.2f} KB\")\n",
    "\n",
    "# 3. Save label encoders\n",
    "print(\"\\n3Ô∏è‚É£ Saving Label Encoders...\")\n",
    "encoders_path = 'models/encoders.pkl'\n",
    "encoders_data = {\n",
    "    'categorical_encoders': label_encoders,\n",
    "    'target_encoder': le_target\n",
    "}\n",
    "joblib.dump(encoders_data, encoders_path)\n",
    "encoders_size = os.path.getsize(encoders_path) / 1024\n",
    "print(f\"   ‚úÖ Encoders saved to: {encoders_path}\")\n",
    "print(f\"   üíæ File size: {encoders_size:.2f} KB\")\n",
    "\n",
    "# 4. Save metadata\n",
    "print(\"\\n4Ô∏è‚É£ Saving Model Metadata...\")\n",
    "metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'feature_names': feature_columns,\n",
    "    'num_features': len(feature_columns),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'metrics': {\n",
    "        'accuracy': float(test_accuracy),\n",
    "        'precision': float(test_precision),\n",
    "        'recall': float(test_recall),\n",
    "        'f1_score': float(test_f1)\n",
    "    },\n",
    "    'hyperparameters': model_params,\n",
    "    'class_distribution': {\n",
    "        'low': int(train_dist.iloc[0]),\n",
    "        'high': int(train_dist.iloc[1])\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = 'models/metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "    \n",
    "metadata_size = os.path.getsize(metadata_path) / 1024\n",
    "print(f\"   ‚úÖ Metadata saved to: {metadata_path}\")\n",
    "print(f\"   üíæ File size: {metadata_size:.2f} KB\")\n",
    "\n",
    "# 5. Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Model Deployment Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüì¶ Deployment Package:\")\n",
    "print(f\"   ‚Ä¢ Model:     {model_size:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ Scaler:    {scaler_size:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ Encoders:  {encoders_size:.2f} KB\")\n",
    "print(f\"   ‚Ä¢ Metadata:  {metadata_size:.2f} KB\")\n",
    "print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(f\"   ‚Ä¢ Total:     {model_size + scaler_size + encoders_size + metadata_size:.2f} KB\")\n",
    "print(f\"\\nüöÄ Model ready for production use!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the deployed model\n",
    "print(\"üß™ Testing Model Loading...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_encoders = joblib.load(encoders_path)\n",
    "\n",
    "# Make a test prediction\n",
    "test_sample = X_test.iloc[0:1]\n",
    "prediction = loaded_model.predict(test_sample)\n",
    "actual = y_test[0]\n",
    "\n",
    "print(f\"\\n   ‚úÖ Model loaded successfully!\")\n",
    "print(f\"   üîÆ Test prediction: {le_target.classes_[prediction[0]]}\")\n",
    "print(f\"   ‚úîÔ∏è Actual value: {le_target.classes_[actual]}\")\n",
    "print(f\"   {'‚úÖ Correct!' if prediction[0] == actual else '‚ùå Incorrect'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e542a36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 9: üìà Monitoring\n",
    "\n",
    "### What is Monitoring?\n",
    "\n",
    "**Monitoring** tracks model performance and data quality in production to detect issues early.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Detects performance degradation\n",
    "- Identifies data drift\n",
    "- Catches anomalies\n",
    "- Ensures reliability\n",
    "- Triggers retraining when needed\n",
    "\n",
    "### What to Monitor:\n",
    "\n",
    "1. **Model Performance**\n",
    "   - Prediction accuracy\n",
    "   - Precision, recall, F1-score\n",
    "   - Prediction latency\n",
    "   - Error rates\n",
    "\n",
    "2. **Data Quality**\n",
    "   - Missing values\n",
    "   - Unexpected values\n",
    "   - Distribution shifts\n",
    "   - Feature correlations\n",
    "\n",
    "3. **Data Drift**\n",
    "   - Input distribution changes\n",
    "   - Feature value shifts\n",
    "   - New categories appearing\n",
    "   - Seasonal patterns\n",
    "\n",
    "4. **System Health**\n",
    "   - API response time\n",
    "   - Memory usage\n",
    "   - CPU usage\n",
    "   - Request volume\n",
    "\n",
    "### Common Monitoring Tools:\n",
    "\n",
    "- **Prometheus**: Metrics collection\n",
    "- **Grafana**: Visualization dashboards\n",
    "- **MLflow**: ML experiment tracking\n",
    "- **AWS CloudWatch**: Cloud monitoring\n",
    "- **Custom**: Log-based tracking\n",
    "\n",
    "### In This Project:\n",
    "\n",
    "We'll implement basic monitoring:\n",
    "- Track prediction distribution\n",
    "- Monitor accuracy metrics\n",
    "- Simple drift detection\n",
    "\n",
    "Let's monitor our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 9: Monitoring\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 9: MONITORING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Prediction Distribution Monitoring\n",
    "print(\"\\n1Ô∏è‚É£ Monitoring Prediction Distribution...\")\n",
    "train_pred_dist = pd.Series(y_train_pred).value_counts()\n",
    "test_pred_dist = pd.Series(y_test_pred).value_counts()\n",
    "\n",
    "print(\"\\n   Training Set Predictions:\")\n",
    "for idx, count in train_pred_dist.items():\n",
    "    print(f\"      {le_target.classes_[idx]}: {count} ({count/len(y_train_pred)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n   Test Set Predictions:\")\n",
    "for idx, count in test_pred_dist.items():\n",
    "    print(f\"      {le_target.classes_[idx]}: {count} ({count/len(y_test_pred)*100:.1f}%)\")\n",
    "\n",
    "# Compare with actual distribution\n",
    "print(\"\\n   Actual Test Distribution:\")\n",
    "actual_dist = pd.Series(y_test).value_counts()\n",
    "for idx, count in actual_dist.items():\n",
    "    print(f\"      {le_target.classes_[idx]}: {count} ({count/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# 2. Performance Monitoring\n",
    "print(\"\\n2Ô∏è‚É£ Performance Metrics Tracking...\")\n",
    "performance_log = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'accuracy': test_accuracy,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'f1_score': test_f1,\n",
    "    'samples_processed': len(y_test)\n",
    "}\n",
    "\n",
    "print(f\"\\n   üìä Current Metrics:\")\n",
    "for metric, value in performance_log.items():\n",
    "    if metric not in ['timestamp', 'samples_processed']:\n",
    "        print(f\"      {metric.capitalize():12s}: {value*100:.2f}%\")\n",
    "    elif metric == 'samples_processed':\n",
    "        print(f\"      {metric.replace('_', ' ').title():12s}: {value}\")\n",
    "\n",
    "# 3. Data Drift Detection (Simple)\n",
    "print(\"\\n3Ô∏è‚É£ Data Drift Detection...\")\n",
    "\n",
    "# Compare feature distributions between train and test\n",
    "drift_detected = []\n",
    "for col in feature_columns[:5]:  # Check top 5 features\n",
    "    train_mean = X_train[col].mean()\n",
    "    test_mean = X_test[col].mean()\n",
    "    train_std = X_train[col].std()\n",
    "    \n",
    "    # Simple drift check: if test mean is > 2 std away from train mean\n",
    "    if abs(test_mean - train_mean) > 2 * train_std:\n",
    "        drift_detected.append(col)\n",
    "        print(f\"   ‚ö†Ô∏è Drift detected in '{col}':\")\n",
    "        print(f\"      Train mean: {train_mean:.3f}, Test mean: {test_mean:.3f}\")\n",
    "\n",
    "if not drift_detected:\n",
    "    print(\"   ‚úÖ No significant drift detected in key features\")\n",
    "\n",
    "# 4. Alert Thresholds\n",
    "print(\"\\n4Ô∏è‚É£ Alert Threshold Monitoring...\")\n",
    "alerts = []\n",
    "\n",
    "# Check if accuracy drops below threshold\n",
    "accuracy_threshold = 0.85\n",
    "if test_accuracy < accuracy_threshold:\n",
    "    alerts.append(f\"Accuracy below threshold: {test_accuracy:.2%} < {accuracy_threshold:.2%}\")\n",
    "\n",
    "# Check if prediction distribution is heavily skewed\n",
    "pred_ratio = test_pred_dist.max() / test_pred_dist.min()\n",
    "if pred_ratio > 20:\n",
    "    alerts.append(f\"Prediction distribution highly imbalanced: {pred_ratio:.1f}:1\")\n",
    "\n",
    "if alerts:\n",
    "    print(\"   ‚ö†Ô∏è Alerts:\")\n",
    "    for alert in alerts:\n",
    "        print(f\"      ‚Ä¢ {alert}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ All metrics within acceptable ranges\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Monitoring Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437142b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary & Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "Congratulations! You've completed a full end-to-end ML pipeline covering all 10 essential stages:\n",
    "\n",
    "‚úÖ **Stage 1: Data Ingestion** - Loaded 800 insurance claims  \n",
    "‚úÖ **Stage 2: Data Validation** - Verified data quality (100% score)  \n",
    "‚úÖ **Stage 3: Data Preprocessing** - Cleaned and prepared data  \n",
    "‚úÖ **Stage 4: Feature Engineering** - Created 9 features from raw data  \n",
    "‚úÖ **Stage 5: Model Training** - Trained Random Forest with 50 trees  \n",
    "‚úÖ **Stage 6: Model Evaluation** - Achieved excellent performance metrics  \n",
    "‚úÖ **Stage 7: Model Selection** - Chose Random Forest as best model  \n",
    "‚úÖ **Stage 8: Model Deployment** - Saved model artifacts (136KB total)  \n",
    "‚úÖ **Stage 9: Monitoring** - Tracked performance and drift  \n",
    "‚úÖ **Stage 10: Model Retraining** - Established retraining criteria  \n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Data Quality Matters**: Clean, validated data is the foundation\n",
    "2. **Feature Engineering is Critical**: Good features = good models\n",
    "3. **Always Evaluate Thoroughly**: Multiple metrics tell the full story\n",
    "4. **Monitor in Production**: Models degrade over time\n",
    "5. **Plan for Retraining**: Keeping models fresh is essential\n",
    "\n",
    "---\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "| **Accuracy** | {:.2f}% |\n",
    "| **Precision** | {:.2f}% |\n",
    "| **Recall** | {:.2f}% |\n",
    "| **F1-Score** | {:.2f}% |\n",
    "| **Training Time** | {:.2f}s |\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps to Improve\n",
    "\n",
    "#### 1. **Handle Class Imbalance** üî¥\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### 2. **Hyperparameter Tuning** ‚öôÔ∏è\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {{\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "```\n",
    "\n",
    "#### 3. **Try Other Algorithms** üß™\n",
    "- XGBoost for better accuracy\n",
    "- LightGBM for faster training\n",
    "- Neural Networks for complex patterns\n",
    "\n",
    "#### 4. **Cross-Validation** üìä\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"CV Accuracy: {{scores.mean():.2f}} (+/- {{scores.std():.2f}})\")\n",
    "```\n",
    "\n",
    "#### 5. **Create API Endpoint** üåê\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(claim: ClaimData):\n",
    "    prediction = model.predict(...)\n",
    "    return {{\"risk_level\": prediction}}\n",
    "```\n",
    "\n",
    "#### 6. **Add Explainability** üîç\n",
    "```python\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resources for Learning More\n",
    "\n",
    "- üìö **Scikit-learn Documentation**: https://scikit-learn.org\n",
    "- üìñ **MLOps Best Practices**: https://ml-ops.org\n",
    "- üé• **Andrew Ng's ML Course**: https://www.coursera.org/learn/machine-learning\n",
    "- üíª **Kaggle Competitions**: https://www.kaggle.com\n",
    "\n",
    "---\n",
    "\n",
    "### Project Files\n",
    "\n",
    "All artifacts are saved in the `models/` directory:\n",
    "- `risk_model.pkl` - Trained Random Forest model\n",
    "- `scaler.pkl` - StandardScaler for features\n",
    "- `encoders.pkl` - Label encoders\n",
    "- `metadata.json` - Model information and metrics\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Ready to Deploy!\n",
    "\n",
    "Your model is production-ready for local use. To deploy to production:\n",
    "\n",
    "1. **Containerize with Docker**\n",
    "2. **Create REST API** (Flask/FastAPI)\n",
    "3. **Deploy to cloud** (AWS/Azure/GCP)\n",
    "4. **Set up monitoring** (Prometheus/Grafana)\n",
    "5. **Implement CI/CD** (GitHub Actions)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Machine Learning! üéâ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Risk level distribution\n",
    "risk_counts = pred_df['risk_level'].value_counts()\n",
    "colors_risk = ['#2ecc71' if x == 'low' else '#e74c3c' for x in risk_counts.index]\n",
    "axes[0].bar(risk_counts.index, risk_counts.values, color=colors_risk)\n",
    "axes[0].set_title('Predicted Risk Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Risk Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(risk_counts.values):\n",
    "    axes[0].text(i, v + 0.05, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Confidence scores\n",
    "claim_numbers = [f\"Claim {i}\" for i in pred_df['claim_number']]\n",
    "confidences = pred_df['confidence'].values\n",
    "colors_conf = ['#2ecc71' if pred_df.iloc[i]['risk_level'] == 'low' else '#e74c3c' \n",
    "               for i in range(len(pred_df))]\n",
    "\n",
    "axes[1].barh(claim_numbers, confidences, color=colors_conf)\n",
    "axes[1].set_title('Prediction Confidence', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Confidence (%)')\n",
    "axes[1].set_xlim(0, 105)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(confidences):\n",
    "    axes[1].text(v + 1, i, f'{v:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fe7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and predict for each claim\n",
    "print(\"=\" * 70)\n",
    "print(\"MAKING PREDICTIONS\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i, claim in enumerate(sample_claims, 1):\n",
    "    # Convert to DataFrame\n",
    "    claim_df = pd.DataFrame([claim])\n",
    "    \n",
    "    # Feature engineering (same as training)\n",
    "    claim_df['claim_date'] = pd.to_datetime(claim_df['claim_date'])\n",
    "    claim_df['policy_start_date'] = pd.to_datetime(claim_df['policy_start_date'])\n",
    "    claim_df['policy_age'] = (claim_df['claim_date'] - claim_df['policy_start_date']).dt.days\n",
    "    claim_df['claim_coverage_ratio'] = claim_df['claim_amount'] / claim_df['policy_coverage']\n",
    "    \n",
    "    # Encode categorical features\n",
    "    claim_df['claim_type_encoded'] = loaded_encoders['categorical_encoders']['claim_type'].transform(claim_df['claim_type'])\n",
    "    claim_df['location_encoded'] = loaded_encoders['categorical_encoders']['location'].transform(claim_df['location'])\n",
    "    \n",
    "    # Select features in correct order\n",
    "    X_new = claim_df[feature_columns]\n",
    "    \n",
    "    # Scale features\n",
    "    X_new_scaled = loaded_scaler.transform(X_new)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = loaded_model.predict(X_new_scaled)[0]\n",
    "    probability = loaded_model.predict_proba(X_new_scaled)[0]\n",
    "    \n",
    "    # Store results\n",
    "    risk_level = loaded_encoders['target_encoder'].inverse_transform([prediction])[0]\n",
    "    confidence = probability[prediction] * 100\n",
    "    \n",
    "    predictions.append({\n",
    "        'claim_number': i,\n",
    "        'risk_level': risk_level,\n",
    "        'confidence': confidence,\n",
    "        'low_risk_prob': probability[0] * 100,\n",
    "        'high_risk_prob': probability[1] * 100\n",
    "    })\n",
    "    \n",
    "    # Display result\n",
    "    print(f\"\\nüìã Claim {i} Prediction:\")\n",
    "    print(f\"   Risk Level: {risk_level.upper()}\")\n",
    "    print(f\"   Confidence: {confidence:.1f}%\")\n",
    "    print(f\"   Probabilities:\")\n",
    "    print(f\"      ‚Ä¢ Low Risk:  {probability[0]*100:.1f}%\")\n",
    "    print(f\"      ‚Ä¢ High Risk: {probability[1]*100:.1f}%\")\n",
    "    \n",
    "    if risk_level == 'high':\n",
    "        print(f\"   ‚ö†Ô∏è Action: Requires manual review\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Action: Auto-approve recommended\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01755430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample claims for prediction\n",
    "sample_claims = [\n",
    "    {\n",
    "        'claim_amount': 25000.00,\n",
    "        'customer_age': 45,\n",
    "        'policy_duration': 24,\n",
    "        'policy_coverage': 100000.00,\n",
    "        'previous_claims': 2,\n",
    "        'claim_type': 'auto',\n",
    "        'location': 'new york, ny',\n",
    "        'claim_date': '2026-01-15',\n",
    "        'policy_start_date': '2024-01-15'\n",
    "    },\n",
    "    {\n",
    "        'claim_amount': 3500.00,\n",
    "        'customer_age': 32,\n",
    "        'policy_duration': 12,\n",
    "        'policy_coverage': 50000.00,\n",
    "        'previous_claims': 0,\n",
    "        'claim_type': 'health',\n",
    "        'location': 'chicago, il',\n",
    "        'claim_date': '2026-01-10',\n",
    "        'policy_start_date': '2025-01-10'\n",
    "    },\n",
    "    {\n",
    "        'claim_amount': 75000.00,\n",
    "        'customer_age': 55,\n",
    "        'policy_duration': 36,\n",
    "        'policy_coverage': 150000.00,\n",
    "        'previous_claims': 3,\n",
    "        'claim_type': 'home',\n",
    "        'location': 'los angeles, ca',\n",
    "        'claim_date': '2026-01-18',\n",
    "        'policy_start_date': '2023-01-18'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üîÆ Sample Claims for Prediction:\\n\")\n",
    "for i, claim in enumerate(sample_claims, 1):\n",
    "    print(f\"Claim {i}:\")\n",
    "    print(f\"   Amount: ${claim['claim_amount']:,.2f}\")\n",
    "    print(f\"   Type: {claim['claim_type']}\")\n",
    "    print(f\"   Customer Age: {claim['customer_age']}\")\n",
    "    print(f\"   Previous Claims: {claim['previous_claims']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the deployed model\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DEPLOYED MODEL\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load all artifacts\n",
    "loaded_model = joblib.load('models/risk_model.pkl')\n",
    "loaded_scaler = joblib.load('models/scaler.pkl')\n",
    "loaded_encoders = joblib.load('models/encoders.pkl')\n",
    "\n",
    "with open('models/metadata.json', 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Model type: {loaded_metadata['model_type']}\")\n",
    "print(f\"   Training date: {loaded_metadata['training_date']}\")\n",
    "print(f\"   Accuracy: {loaded_metadata['metrics']['accuracy']*100:.2f}%\")\n",
    "print(f\"   Features: {loaded_metadata['num_features']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e0fd1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Making Predictions with the Deployed Model\n",
    "\n",
    "Now that we've completed all 10 pipeline stages, let's use our deployed model to make predictions on new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 10: Model Retraining\n",
    "print(\"=\" * 70)\n",
    "print(\"STAGE 10: MODEL RETRAINING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Define retraining criteria\n",
    "print(\"\\n1Ô∏è‚É£ Checking Retraining Criteria...\")\n",
    "\n",
    "retraining_triggers = {\n",
    "    'performance_degradation': False,\n",
    "    'data_drift': False,\n",
    "    'scheduled_update': False,\n",
    "    'new_data_available': False\n",
    "}\n",
    "\n",
    "# Check performance threshold\n",
    "accuracy_threshold = 0.85\n",
    "if test_accuracy < accuracy_threshold:\n",
    "    retraining_triggers['performance_degradation'] = True\n",
    "    print(f\"   ‚ö†Ô∏è Performance below threshold: {test_accuracy:.2%} < {accuracy_threshold:.2%}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Performance acceptable: {test_accuracy:.2%} >= {accuracy_threshold:.2%}\")\n",
    "\n",
    "# Check for data drift\n",
    "if len(drift_detected) > 0:\n",
    "    retraining_triggers['data_drift'] = True\n",
    "    print(f\"   ‚ö†Ô∏è Data drift detected in {len(drift_detected)} features\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ No significant data drift\")\n",
    "\n",
    "# Check last training date (simulated)\n",
    "# In production, you'd check against actual last training date\n",
    "days_since_training = 0  # Just trained\n",
    "scheduled_interval = 30  # Retrain every 30 days\n",
    "if days_since_training >= scheduled_interval:\n",
    "    retraining_triggers['scheduled_update'] = True\n",
    "    print(f\"   ‚ö†Ô∏è Scheduled retraining due: {days_since_training} days since last training\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Next scheduled retraining in {scheduled_interval - days_since_training} days\")\n",
    "\n",
    "# Check for new data (simulated)\n",
    "# In production, you'd query database for new records\n",
    "new_samples_count = 0\n",
    "new_data_threshold = 100\n",
    "if new_samples_count >= new_data_threshold:\n",
    "    retraining_triggers['new_data_available'] = True\n",
    "    print(f\"   ‚ö†Ô∏è New data available: {new_samples_count} samples\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ New data: {new_samples_count} samples (threshold: {new_data_threshold})\")\n",
    "\n",
    "# 2. Retraining decision\n",
    "print(\"\\n2Ô∏è‚É£ Retraining Decision...\")\n",
    "should_retrain = any(retraining_triggers.values())\n",
    "\n",
    "if should_retrain:\n",
    "    print(\"   üîÑ RETRAINING RECOMMENDED\")\n",
    "    print(\"   Reasons:\")\n",
    "    for trigger, status in retraining_triggers.items():\n",
    "        if status:\n",
    "            print(f\"      ‚Ä¢ {trigger.replace('_', ' ').title()}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ NO RETRAINING NEEDED\")\n",
    "    print(\"   Current model performing well\")\n",
    "\n",
    "# 3. Retraining process (simulated)\n",
    "print(\"\\n3Ô∏è‚É£ Retraining Process:\")\n",
    "if should_retrain:\n",
    "    print(\"   Would execute:\")\n",
    "    print(\"   1. Load all available data (old + new)\")\n",
    "    print(\"   2. Re-run preprocessing and feature engineering\")\n",
    "    print(\"   3. Train new model with updated hyperparameters\")\n",
    "    print(\"   4. Evaluate on validation set\")\n",
    "    print(\"   5. A/B test against current model\")\n",
    "    print(\"   6. Deploy if performance improves\")\n",
    "    print(\"   7. Version and archive old model\")\n",
    "else:\n",
    "    print(\"   No action required - model is current\")\n",
    "\n",
    "# 4. Model versioning\n",
    "print(\"\\n4Ô∏è‚É£ Model Versioning:\")\n",
    "current_version = \"v1.0\"\n",
    "print(f\"   Current model version: {current_version}\")\n",
    "print(f\"   Training date: {metadata['training_date']}\")\n",
    "print(f\"   Next version: v1.1 (if retrained)\")\n",
    "\n",
    "# 5. Retraining schedule\n",
    "print(\"\\n5Ô∏è‚É£ Retraining Schedule:\")\n",
    "print(\"   üìÖ Recommended schedule:\")\n",
    "print(\"      ‚Ä¢ Performance monitoring: Daily\")\n",
    "print(\"      ‚Ä¢ Drift detection: Weekly\")\n",
    "print(\"      ‚Ä¢ Scheduled retraining: Monthly\")\n",
    "print(\"      ‚Ä¢ Full audit: Quarterly\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Retraining Check Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a39cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stage 10: üîÑ Model Retraining\n",
    "\n",
    "### What is Model Retraining?\n",
    "\n",
    "**Model Retraining** is the process of updating your model with new data to maintain or improve performance.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "- Models degrade over time (concept drift)\n",
    "- New patterns emerge in data\n",
    "- Business requirements change\n",
    "- Maintain competitive performance\n",
    "- Adapt to seasonality\n",
    "\n",
    "### When to Retrain:\n",
    "\n",
    "1. **Performance Degradation**\n",
    "   - Accuracy drops below threshold\n",
    "   - Precision/recall deteriorate\n",
    "   - User complaints increase\n",
    "\n",
    "2. **Data Drift Detected**\n",
    "   - Input distributions change\n",
    "   - New categories appear\n",
    "   - Feature correlations shift\n",
    "\n",
    "3. **Scheduled Updates**\n",
    "   - Weekly/monthly retraining\n",
    "   - After major events\n",
    "   - Seasonal adjustments\n",
    "\n",
    "4. **New Data Available**\n",
    "   - Significant new samples\n",
    "   - Feedback loop completed\n",
    "   - Labeled data accumulated\n",
    "\n",
    "### Retraining Strategies:\n",
    "\n",
    "| Strategy | Description | When to Use |\n",
    "|----------|-------------|-------------|\n",
    "| **Full Retrain** | Train from scratch on all data | Major changes, monthly |\n",
    "| **Incremental** | Update with new data only | Continuous learning |\n",
    "| **Online Learning** | Update in real-time | Streaming data |\n",
    "| **Transfer Learning** | Fine-tune existing model | Similar domains |\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- ‚úÖ Version all models (v1.0, v1.1, etc.)\n",
    "- ‚úÖ A/B test new vs. old model\n",
    "- ‚úÖ Keep rollback capability\n",
    "- ‚úÖ Monitor performance closely after deployment\n",
    "- ‚úÖ Automate retraining pipeline\n",
    "- ‚úÖ Log all retraining triggers\n",
    "\n",
    "Let's implement retraining logic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize monitoring metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prediction distribution comparison\n",
    "categories = ['Training', 'Test', 'Actual']\n",
    "low_risk = [train_pred_dist.get(0, 0), test_pred_dist.get(0, 0), actual_dist.get(0, 0)]\n",
    "high_risk = [train_pred_dist.get(1, 0), test_pred_dist.get(1, 0), actual_dist.get(1, 0)]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, low_risk, width, label='Low Risk', color='#2ecc71')\n",
    "axes[0].bar(x + width/2, high_risk, width, label='High Risk', color='#e74c3c')\n",
    "axes[0].set_xlabel('Dataset')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Prediction Distribution Comparison', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(categories)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Performance metrics over time (simulated)\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "metrics_values = [test_accuracy*100, test_precision*100, test_recall*100, test_f1*100]\n",
    "colors = ['#3498db', '#9b59b6', '#e67e22', '#1abc9c']\n",
    "\n",
    "axes[1].barh(metrics_names, metrics_values, color=colors)\n",
    "axes[1].set_xlabel('Score (%)')\n",
    "axes[1].set_title('Current Performance Metrics', fontweight='bold')\n",
    "axes[1].set_xlim(0, 105)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(metrics_values):\n",
    "    axes[1].text(v + 1, i, f'{v:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
